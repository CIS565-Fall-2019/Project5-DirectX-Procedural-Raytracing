**University of Pennsylvania, CIS 565: GPU Programming and Architecture,
Project 5 - DirectX Procedural Raytracing**

* SOMANSHU AGARWAL
  * [LinkedIn](https://www.linkedin.com/in/somanshu25)
* Tested on: Windows 10, i7-6700 @ 3.4GHz 16GB, Quadro P1000 4GB (Moore 100B Lab)

![](https://github.com/somanshu25/Project5-DirectX-Procedural-Raytracing/blob/master/images/gif_scene_new.gif)

### Table of Contents

1. [Introduction](#Introduction)
2. [RayTracing](#RayTracing)
3. [Code Section](#Code-Section)
4. [Performace Analysis](#Performace-Analysis)
5. [Bloopers](#Bloopers)
6. [References](#References)

### Introduction
The project aims at doing ray tracing rendering of a scene using DXR API. The issue with raytracing with the geometries is that we need all the shadeers at once for perfroming rendering, which requires lot of computation and almost impossible to do. The Microsoft came up with DXR API's which help use to perform the rayracing thorugh lot of optimization techniques. The steps in the project helped to learn how the pipeline is generated by using CPU code and how the logic for rendering is written using GPU kernels and parallel computation is used for processing.

The readme gives the brief understanding about the raytracing, about the CPU and GPU codes and finally a performace analysis of the DXR rattrcing with trying the maximum depth of a ray. I have included some bloopers in the end to mention some of my mistakes I was ding while coding in the project.

### RayTracing

Raytracing is the technique used to render scenes and created the images. In raytracing, when a ray from the camera through the pixel co-rodinate of the screen space to the object, which is `radiance ray`,, we find the position and the normal corresponding to the intersection between the object geomentry and the ray. To render the object at the position, we create a light ray which goes to the light source (it's a point source in raytracing) and check whether it is blocked by some other geometry on the way to the light source. If it is blocked, then it's called a `shadow ray` and we render the shadow(black) color at that position. If it goes directly to the light source, we render the color of the obejct. We render the backgorund color if it misses our place surface(made of two triangles) and geometries, it is rendered as a background color. If the object is reflective, then we generate two rays, one which goes to the light source and the other as reflective ray which follows the same logic as radiance ray above. The ray is meant ot be dead if it bounces more than the maximum recursion depth of the ray. 

<p align="center"><img src="https://github.com/somanshu25/Project5-DirectX-Procedural-Raytracing/blob/master/images/raytrace.jpg" width="500"/></p>

### Code Section:

While coding, the parts are divided into tow main parts: CPU and GPU section codes.

a. In CPU section, we create the pipeline which could be later on used by the GPU section to render. Note that in raytracing, we need to make sure that all the data is available when the GPU is doing the rendering as compared to rasterization. So, we store the geometries in CPU section of the code and for GPU to access the GPU section, we create dynamic allocation of the memory in the heap and define the dscriptors which gives us the mapping of the CPU and GPU pointers. Here, to create a scene, we first create a transformation of all the objects in their local space (each of then can have their own coordinate space) to the bottom level space which has the same reference coordinate system. After getting the bottom level, we then create the transformation to the scene by creating the instance of the bottom level geometries (also called as Bottom Level Accelearted Structure here) and creating a scene as the Top-Level Accelerated Structure, which we see as the visualization. In our case, we are dealing with two types of geometries, geometries defined by vertices and indices and the other as procedural geometires defined through Axis Aligned Geometry Box(AABB).

<p align="center"><img src="https://github.com/somanshu25/Project5-DirectX-Procedural-Raytracing/blob/master/images/pipeline.png" width="500"/></p>

b. In GPU section, we perform the ray generation from the camera which goes from the camera to the world space with the given information of the pixel co-ordinate of the sreeen space and the camera to world projection transformation. Using the ray generated, we perform the intersection test for all the geometries at local space of the geometry, where we can get through teh inverse transformation of the matrix we got from going to local space to the bottom level space. Once finding the poition and normal of the position if it intersects, we render the poision using raytracing algorithm. We create the shades for the miss also so that we can render those points as some colors in our screen space. In our case, we have intersection test for triangel geometries, test for Analytical Primities (includes AABB Box, Sphere) and the MetaBalls. The references used for intersection tests are provided at the [last section of the readme](#References). We create the hitgroups for pair of each genpmetry and ray. Among the geomtries/hitgroups it intersected, we take the closest hit geometry and render the point.

### Performance Analysis

In one of the steps after wrting the CPU code, ray generation and TraceRay() fucntion and Miss shaders , here is the image how it looks like with the Analytical Primitives (AABB Box and Spheres):

<p align="center"><img src="https://github.com/somanshu25/Project5-DirectX-Procedural-Raytracing/blob/master/images/Capture1.PNG" width="600"/></p>


The performance analysis of FPS with varying the depth is shown below:

<p align="center"><img src="https://github.com/somanshu25/Project5-DirectX-Procedural-Raytracing/blob/master/images/imageChart.png" width="700"/></p>

We see that the FPS is decreasing as we are increasing the maximum depth of the ray which is expected.

### Bloopers

Some of the bloopers are below:

1. The folwwing happened when I was calculating the potential for the Metaball. I was creating the inverse functino from cetner to radii but should have been the opposite.

<p align="center"><img src="https://github.com/somanshu25/Project5-DirectX-Procedural-Raytracing/blob/master/images/capture2.PNG" width="600"/></p>

2. Also, I didn't have the linear interpolate function correctly because of which I couldn't differentiate between the lan and the background.

<p align="center"><img src="https://github.com/somanshu25/Project5-DirectX-Procedural-Raytracing/blob/master/images/capture_no_plane_background_diff.PNG" width="600"/></p>

## References

